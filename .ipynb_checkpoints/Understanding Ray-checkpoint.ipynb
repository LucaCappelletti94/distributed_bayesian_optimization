{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-05-13 15:06:22,392\tWARNING ray_trial_executor.py:480 -- Cluster resources not detected or are 0. Attempt #2...\n",
      "2020-05-13 15:06:22,895\tWARNING ray_trial_executor.py:480 -- Cluster resources not detected or are 0. Attempt #3...\n",
      "2020-05-13 15:06:23,397\tWARNING ray_trial_executor.py:480 -- Cluster resources not detected or are 0. Attempt #4...\n",
      "2020-05-13 15:06:23,899\tWARNING ray_trial_executor.py:480 -- Cluster resources not detected or are 0. Attempt #5...\n",
      "2020-05-13 15:06:24,401\tWARNING ray_trial_executor.py:497 -- Cluster resources cannot be detected or are 0. You can resume this experiment by passing in `resume=True` to `run`.\n",
      "2020-05-13 15:06:24,408\tWARNING ray_trial_executor.py:480 -- Cluster resources not detected or are 0. Attempt #2...\n",
      "2020-05-13 15:06:24,910\tWARNING ray_trial_executor.py:480 -- Cluster resources not detected or are 0. Attempt #3...\n",
      "2020-05-13 15:06:25,412\tWARNING ray_trial_executor.py:480 -- Cluster resources not detected or are 0. Attempt #4...\n",
      "2020-05-13 15:06:25,915\tWARNING ray_trial_executor.py:480 -- Cluster resources not detected or are 0. Attempt #5...\n",
      "2020-05-13 15:06:26,417\tWARNING ray_trial_executor.py:497 -- Cluster resources cannot be detected or are 0. You can resume this experiment by passing in `resume=True` to `run`.\n",
      "2020-05-13 15:06:26,419\tWARNING ray_trial_executor.py:480 -- Cluster resources not detected or are 0. Attempt #2...\n",
      "2020-05-13 15:06:26,921\tWARNING ray_trial_executor.py:480 -- Cluster resources not detected or are 0. Attempt #3...\n",
      "2020-05-13 15:06:27,423\tWARNING ray_trial_executor.py:480 -- Cluster resources not detected or are 0. Attempt #4...\n",
      "2020-05-13 15:06:27,925\tWARNING ray_trial_executor.py:480 -- Cluster resources not detected or are 0. Attempt #5...\n",
      "2020-05-13 15:06:28,427\tWARNING ray_trial_executor.py:497 -- Cluster resources cannot be detected or are 0. You can resume this experiment by passing in `resume=True` to `run`.\n",
      "2020-05-13 15:06:28,428\tWARNING util.py:137 -- The `on_step_begin` operation took 2.0098750591278076 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "ename": "TuneError",
     "evalue": "Insufficient cluster resources to launch trial: trial requested 1 CPUs, 0 GPUs but the cluster has only 0 CPUs, 0 GPUs, 0.0 GiB heap, 0.0 GiB objects. Pass `queue_trials=True` in ray.tune.run() or on the command line to queue trials until the cluster scales up or resources become available. ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTuneError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-30deaa48b3eb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mresources_per_trial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"gpu\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     config={\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0;34m\"x\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtune\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     }\n\u001b[1;32m     14\u001b[0m )\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/ray/tune/tune.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(run_or_experiment, name, stop, config, resources_per_trial, num_samples, local_dir, upload_dir, trial_name_creator, loggers, sync_to_cloud, sync_to_driver, checkpoint_freq, checkpoint_at_end, sync_on_checkpoint, keep_checkpoints_num, checkpoint_score_attr, global_checkpoint_period, export_formats, max_failures, fail_fast, restore, search_alg, scheduler, with_server, server_port, verbose, progress_reporter, resume, queue_trials, reuse_actors, trial_executor, raise_on_failed_trial, return_trials, ray_auto_init)\u001b[0m\n\u001b[1;32m    323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_finished\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m         \u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m             \u001b[0m_report_progress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrunner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprogress_reporter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/ray/tune/trial_runner.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    339\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# blocking\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 341\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrial_executor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_no_available_trials\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stop_experiment_if_needed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/ray/tune/trial_executor.py\u001b[0m in \u001b[0;36mon_no_available_trials\u001b[0;34m(self, trial_runner)\u001b[0m\n\u001b[1;32m    173\u001b[0m                              \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresource_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m                              trial.get_trainable_cls().resource_help(\n\u001b[0;32m--> 175\u001b[0;31m                                  trial.config)))\n\u001b[0m\u001b[1;32m    176\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mTrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPAUSED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m                 raise TuneError(\"There are paused trials, but no more pending \"\n",
      "\u001b[0;31mTuneError\u001b[0m: Insufficient cluster resources to launch trial: trial requested 1 CPUs, 0 GPUs but the cluster has only 0 CPUs, 0 GPUs, 0.0 GiB heap, 0.0 GiB objects. Pass `queue_trials=True` in ray.tune.run() or on the command line to queue trials until the cluster scales up or resources become available. "
     ]
    }
   ],
   "source": [
    "from ray import tune\n",
    "from ray.tune.suggest import BasicVariantGenerator\n",
    "\n",
    "\n",
    "def my_func(config, reporter):\n",
    "    reporter(-config[\"x\"]**2)\n",
    "\n",
    "tune.run(\n",
    "    my_func,\n",
    "    resources_per_trial={\"cpu\":1, \"gpu\":0},\n",
    "    config={\n",
    "        \"x\": tune.uniform(0, 20),\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
